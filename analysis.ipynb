{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f2e8337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 JSON files to process...\n",
      "Processed: 0.json\n",
      "Processed: 1.json\n",
      "Processed: 2.json\n",
      "Processed: 3.json\n",
      "Processed: 4.json\n",
      "\n",
      "Successfully converted 750 records to tests/attempts_data/baseline_attempts.csv\n",
      "CSV shape: (750, 14)\n",
      "Columns: ['sid', 'att_n', 'e1', 'e2', 'ok', 'res', 'inv_b4', 'reason', 'novel', 'str_typ', 'str_len', 't_since', '_timestamp', '_datetime']\n",
      "Found 5 JSON files to process...\n",
      "Processed: 0.json\n",
      "Processed: 1.json\n",
      "Processed: 2.json\n",
      "Processed: 3.json\n",
      "Processed: 4.json\n",
      "\n",
      "Successfully converted 5 records to tests/sessions_data/baseline_sessions.csv\n",
      "CSV shape: (5, 15)\n",
      "Columns: ['sid', 'r_typ', 'start', 'start_ts', 'end', 'end_ts', 'tot_att', 'succ_att', 'elem_disc', 'final_inv', 'disc_rate', 'max_succ', 'max_fail', 'plateaus', 'last_disc_t']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def json_folder_to_csv(folder_path, output_csv_path):\n",
    "    \"\"\"\n",
    "    Convert all JSON files in a folder to a single CSV file.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to folder containing JSON files\n",
    "        output_csv_path (str): Path for output CSV file\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    # Get all JSON files in the folder\n",
    "    folder = Path(folder_path)\n",
    "    json_files = list(folder.glob(\"*.json\"))\n",
    "    \n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in {folder_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(json_files)} JSON files to process...\")\n",
    "    \n",
    "    # Process each JSON file\n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            # Handle both single objects and arrays\n",
    "            if isinstance(data, list):\n",
    "                all_data.extend(data)\n",
    "            else:\n",
    "                all_data.append(data)\n",
    "                \n",
    "            print(f\"Processed: {json_file.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {json_file.name}: {e}\")\n",
    "    \n",
    "    if not all_data:\n",
    "        print(\"No data found in JSON files\")\n",
    "        return\n",
    "    \n",
    "    # Convert to DataFrame and save as CSV\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "    print(f\"\\nSuccessfully converted {len(all_data)} records to {output_csv_path}\")\n",
    "    print(f\"CSV shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Example usage:\n",
    "# Convert attempts folder to CSV\n",
    "json_folder_to_csv(\"tests/datasets/baseline/attempts/\", \"tests/attempts_data/baseline_attempts.csv\")\n",
    "\n",
    "# Convert sessions folder to CSV\n",
    "json_folder_to_csv(\"tests/datasets/baseline/sessions/\", \"tests/sessions_data/baseline_sessions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6388c70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 CSV files to concatenate...\n",
      "Loaded: conterfactual_attempts.csv (729 rows)\n",
      "Loaded: baseline_attempts.csv (750 rows)\n",
      "Loaded: abductive_attempts.csv (705 rows)\n",
      "Loaded: heuristic_attempts.csv (724 rows)\n",
      "Loaded: first_principles_attempts.csv (750 rows)\n",
      "\n",
      "Successfully concatenated 5 files to tests/all_attempts_data.csv\n",
      "Combined CSV shape: (3658, 14)\n",
      "Columns: ['sid', 'att_n', 'e1', 'e2', 'ok', 'res', 'inv_b4', 'reason', 'novel', 'str_typ', 'str_len', 't_since', '_timestamp', '_datetime']\n",
      "Found 5 CSV files to concatenate...\n",
      "Loaded: first_principles_sessions.csv (5 rows)\n",
      "Loaded: baseline_sessions.csv (5 rows)\n",
      "Loaded: conterfactual_sessions.csv (5 rows)\n",
      "Loaded: heuristic_sessions.csv (5 rows)\n",
      "Loaded: abductive_sessions.csv (5 rows)\n",
      "\n",
      "Successfully concatenated 5 files to tests/all_sessions_data.csv\n",
      "Combined CSV shape: (25, 15)\n",
      "Columns: ['sid', 'r_typ', 'start', 'start_ts', 'end', 'end_ts', 'tot_att', 'succ_att', 'elem_disc', 'final_inv', 'disc_rate', 'max_succ', 'max_fail', 'plateaus', 'last_disc_t']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def concatenate_csv_files(folder_path, output_csv_path, pattern=\"*.csv\"):\n",
    "    \"\"\"\n",
    "    Concatenate multiple CSV files from a folder into a single CSV file.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to folder containing CSV files\n",
    "        output_csv_path (str): Path for the output concatenated CSV file\n",
    "        pattern (str): File pattern to match (default: \"*.csv\")\n",
    "    \"\"\"\n",
    "    all_dataframes = []\n",
    "    \n",
    "    # Get all CSV files in the folder\n",
    "    folder = Path(folder_path)\n",
    "    csv_files = list(folder.glob(pattern))\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in {folder_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(csv_files)} CSV files to concatenate...\")\n",
    "    \n",
    "    # Process each CSV file\n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            all_dataframes.append(df)\n",
    "            print(f\"Loaded: {csv_file.name} ({df.shape[0]} rows)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {csv_file.name}: {e}\")\n",
    "    \n",
    "    if not all_dataframes:\n",
    "        print(\"No data found in CSV files\")\n",
    "        return\n",
    "    \n",
    "    # Concatenate all DataFrames\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    combined_df.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "    print(f\"\\nSuccessfully concatenated {len(all_dataframes)} files to {output_csv_path}\")\n",
    "    print(f\"Combined CSV shape: {combined_df.shape}\")\n",
    "    print(f\"Columns: {list(combined_df.columns)}\")\n",
    "\n",
    "# Example usage:\n",
    "# Concatenate all attempts data files\n",
    "concatenate_csv_files(\"tests/attempts_data\", \"tests/all_attempts_data.csv\", pattern=\"*.csv\")\n",
    "\n",
    "# Concatenate all sessions data files  \n",
    "concatenate_csv_files(\"tests/sessions_data\", \"tests/all_sessions_data.csv\", pattern=\"*.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
